{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLworkshop_clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBfg3TbAVfMSd+9JtE03gP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drake-HeleneVeenstra/workshops/blob/main/MLworkshop_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sh1C7LWFRZY"
      },
      "source": [
        "# **Klustering algoritmer för segmentering - från statistik till maskininlärning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtcaWLVzWyJg"
      },
      "source": [
        "**1. Som förberedning för klusteringanalys behöver vi ladda in vissa libraries samt skapa data.**\r\n",
        "Dessa libraries innehåller visualiseringsmöjligheter (matplotlib och seaborn) och de faktiska clusterings algoritmer (sklearn.cluster, hdbscan). Numpy underlättar datamanipulering, och sklearn.datasets ger möjlighet att skapa data (liknande 'load inline' in Qlik).\r\n",
        "\r\n",
        "Sen skapar vi data och plottar den. Du kan ändra parametrar i moons och blobs för att ändra datans utseende."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfTBF4kaWxsf"
      },
      "source": [
        "# 1 - skapa dataset och scatterplot\r\n",
        "\r\n",
        "# installation behövs för att kunna köra hdbscan\r\n",
        "!pip install hdbscan\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import sklearn.cluster as cluster\r\n",
        "import sklearn.datasets as data\r\n",
        "import hdbscan\r\n",
        "plot_kwds = {'alpha': 0.5, 's': 80, 'linewidths': 0}\r\n",
        "\r\n",
        "# Här skapar vi data, i form av månar och blobs. Ändra n_samples, noise, centers, cluster_std efter behag\r\n",
        "moons, _ = data.make_moons(n_samples=100, noise=0.05)\r\n",
        "blobs, _ = data.make_blobs(n_samples=100, centers=[(1, 2.25), (-1.0, 1.9)], cluster_std=0.2)\r\n",
        "datastack = np.vstack([moons, blobs])\r\n",
        "\r\n",
        "# Plot:\r\n",
        "plt.scatter(datastack.T[0], datastack.T[1], c='b', **plot_kwds)\r\n",
        "plt.title('1 Scatterplot of generated data', fontsize=20)\r\n",
        "frame = plt.gca()\r\n",
        "frame.axes.get_xaxis().set_visible(False)\r\n",
        "frame.axes.get_yaxis().set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyOI-XEUXQqY"
      },
      "source": [
        "**2a. Vår första algoritm blir en K-means klustering algoritm.** I kwargs-argumentet finns några utvalda hyperparameters definierad som påverkar utfall av klustering. 'n_clusters' bestämmer i hur många kluster datasetet blir uppdelat. 'random_state' bestämmer random seed som utgångspunkt. Att definiera denna betyder samma resultat när man skulle testa algoritmen igen nästa vecka.  Testa att ändra antal clusters i variabeln 'kwargs' from 5 till något annat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQxmuCInXQSt"
      },
      "source": [
        "# 2a - K-means clustering on dataset\r\n",
        "\r\n",
        "kwargs = {'n_clusters': 4, 'random_state': 38}\r\n",
        "\r\n",
        "algorithm = cluster.KMeans\r\n",
        "labels = algorithm(**kwargs).fit_predict(datastack)\r\n",
        "palette = sns.color_palette('muted', np.unique(labels).max() + 1)\r\n",
        "colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\r\n",
        "plt.scatter(datastack.T[0], datastack.T[1], c=colors)\r\n",
        "frame = plt.gca()\r\n",
        "frame.axes.get_xaxis().set_visible(False)\r\n",
        "frame.axes.get_yaxis().set_visible(False)\r\n",
        "plt.title('2a Clustering method: {}'.format(str(algorithm.__name__)),\r\n",
        "          fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKAaX9pheEMd"
      },
      "source": [
        ">K-means är en partitioning algoritm som har som antagandet att det finns globala partitions som är centroid-based. Denna algoritm behöver input om hur många klusters det finns att hitta i datasettet. Prestanda på denna dataset är dålig, den grupperar och segrererar tydlig felaktig, för den kan inte fånga en måna som en segment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38ypU-peHhz0"
      },
      "source": [
        "**2b. Vi tar en närmare titt på hur man kan modifiera andra hyperparametrar än antal kluster för att komma närmare verkligheten.** För det skapar vi ett andra dataset som består utav tre blobs, två nära varandra och en blob med stor spridning längre bort. I denna figur har vi inte än applicerat en klusteringalgoritm, färgerna i scatterplot visar bara hur de tre originalblobs är definierat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI2uW5InO6Vs"
      },
      "source": [
        "# 2b - skapa ny dataset med spridda kluster, och plotta de tre blobs i olika färger\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import sklearn.cluster as cluster\r\n",
        "import sklearn.datasets as data\r\n",
        "plot_kwds = {'alpha': 0.5, 's': 80, 'linewidths': 0}\r\n",
        "\r\n",
        "# Nu skapar vi bara blobs (inga moons), med större spridning\r\n",
        "blobs_tmp_1, _ = data.make_blobs(n_samples=300, centers=[(1.2, 2.25)], cluster_std=0.4)\r\n",
        "blobs_tmp_2, _ = data.make_blobs(n_samples=300, centers=[(2, 1)], cluster_std=0.4)\r\n",
        "blobs_tmp_3, _ = data.make_blobs(n_samples=300, centers=[(20, 5)], cluster_std=5)\r\n",
        "datastack_tmp = np.vstack([blobs_tmp_1, blobs_tmp_2, blobs_tmp_3])\r\n",
        "\r\n",
        "# Plot:\r\n",
        "plt.scatter(blobs_tmp_1.T[0], blobs_tmp_1.T[1], c='b', **plot_kwds)\r\n",
        "plt.scatter(blobs_tmp_2.T[0], blobs_tmp_2.T[1], c='r', **plot_kwds)\r\n",
        "plt.scatter(blobs_tmp_3.T[0], blobs_tmp_3.T[1], c='g', **plot_kwds)\r\n",
        "plt.title('2b Scatterplot of generated data',fontsize=20)\r\n",
        "frame = plt.gca()\r\n",
        "frame.axes.get_xaxis().set_visible(False)\r\n",
        "frame.axes.get_yaxis().set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmhDZfodVsju"
      },
      "source": [
        "**2c. Applicering av en K-means klustering likadant som i 2a**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm3KGhauQGbO"
      },
      "source": [
        "# 2c - K-means algoritm\r\n",
        "\r\n",
        "kwargs_tmp = {'n_clusters': 3, 'random_state': 38, 'init': 'random'}\r\n",
        "\r\n",
        "algorithm = cluster.KMeans\r\n",
        "labels = algorithm(**kwargs_tmp).fit_predict(datastack_tmp)\r\n",
        "palette = sns.color_palette('muted', np.unique(labels).max() + 1)\r\n",
        "colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\r\n",
        "plt.scatter(datastack_tmp.T[0], datastack_tmp.T[1], c=colors)\r\n",
        "frame = plt.gca()\r\n",
        "frame.axes.get_xaxis().set_visible(False)\r\n",
        "frame.axes.get_yaxis().set_visible(False)\r\n",
        "plt.title('2c Clustering method: {}'.format(str(algorithm.__name__)),\r\n",
        "          fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoZtcmzjI5CY"
      },
      "source": [
        "**2d.** Det syns tydlig i figuren 2c ovan att klustering blir fel, stora spridda blobben är egentligen en blob och borde falla i en kluster/segment. De två små blobs till vänster blir sammanslagen i en och samma segment.\r\n",
        "Dock har vi kunskap om vår data, vi vet ju vart blobbens centroid ligger. I riktig data har vi inte exakt information om det, men vi kan ha ungefärlig beskrivning av en centroid. **Vi kan lägga centroids som utgångsinformation för klusterdefinition i modellen:**\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz3Zn1N0PqG3"
      },
      "source": [
        "# 2d - vi definierar centroids som vi hade kunskap om som utgångspunkt av klusterdefinition ('init')\r\n",
        "\r\n",
        "centers=np.asarray([[1, 2.25], [2, 1], [20, 5]])\r\n",
        "kwargs_tmp = {'n_clusters': 3, 'random_state': 38, 'init': centers, 'n_init': 1}\r\n",
        "\r\n",
        "algorithm = cluster.KMeans\r\n",
        "labels = algorithm(**kwargs_tmp).fit_predict(datastack_tmp)\r\n",
        "palette = sns.color_palette('muted', np.unique(labels).max() + 1)\r\n",
        "colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\r\n",
        "plt.scatter(datastack_tmp.T[0], datastack_tmp.T[1], c=colors)\r\n",
        "frame = plt.gca()\r\n",
        "frame.axes.get_xaxis().set_visible(False)\r\n",
        "frame.axes.get_yaxis().set_visible(False)\r\n",
        "plt.title('2d Clustering method: {}'.format(str(algorithm.__name__)),\r\n",
        "          fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAFhWBtvKXaB"
      },
      "source": [
        ">Det finns fler sätt att optimera K-means kluster. T.ex. kan du gå tillbaka till kod i 2c och testa att separera i fler än tre kluster. Blev det bättre resultat?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybUxMHd-atYb"
      },
      "source": [
        "**3.** De månar i vårt originaldataset går inte att separera med en K-means klustering. Vi går vidare och testar flera algoritmer, och ändra några av deras hyperparametrar för att se huruvida dessa går att optimera. **Vi testar en Affinity Propagation algoritm näst**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iMmBatVa5NH"
      },
      "source": [
        "# 3 - Affinity Propagation\r\n",
        "kwargs = {'preference': -6.0, 'damping': 0.85}\r\n",
        "\r\n",
        "algorithm = cluster.AffinityPropagation\r\n",
        "labels = algorithm(**kwargs).fit_predict(datastack)\r\n",
        "palette = sns.color_palette('muted', np.unique(labels).max() + 1)\r\n",
        "colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\r\n",
        "plt.scatter(datastack.T[0], datastack.T[1], c=colors)\r\n",
        "frame = plt.gca()\r\n",
        "frame.axes.get_xaxis().set_visible(False)\r\n",
        "frame.axes.get_yaxis().set_visible(False)\r\n",
        "plt.title('3 Clustering method: {}'.format(str(algorithm.__name__)),\r\n",
        "          fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAuu_IMYRO45"
      },
      "source": [
        ">Affinity Propagation är en graph-baserad point-voting system, följd av en centroid-baserad partitioning approach. Fördelen med den över K-means är att man inte behöver bestämma på förhand hur många segmenter det ska hittas. Nackdelen är att den har inte bättre performance än K-means i denna dataset. Dessutom är de hyperparametrar i denna modell inte lätt-optimerad, dessutom är algoritmen långsammare än K-means. Eftersom denna modell förbättrar inte vårt segmentering jämfört med K-means så diskuterar vi inte den i djupet men går vi vidare."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS2cA-XjYAEy"
      },
      "source": [
        "**4. Mean Shift clustering. Igen en centroid-baserad algoritm. Denna algoritm gör riktig klustering snarare än partitioning.** Skillnaden är att en partitioning algoritm fungerar som en top-down gruppering av alla datapunkter, vilket föredrar en mindre antal större grupper. Partitioning börjar istället bottom-up, och utgår från konnektiviteten mellan punkter. Om vi väljer 'cluster_all': False så visas att inte alla punkter rimligtvis tillhör någon segment. Ändra till True för att tvinga alla punkter att falla i en segment, och se att det försämras segmenteringen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpURiK9jOhS3"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qBm6fOxcBm4"
      },
      "source": [
        "# 4 - Mean Shift clustering\r\n",
        "kwargs = {'cluster_all': False}\r\n",
        "\r\n",
        "algorithm = cluster.MeanShift\r\n",
        "labels = algorithm(0.3, **kwargs).fit_predict(datastack)\r\n",
        "palette = sns.color_palette('muted', np.unique(labels).max() + 1)\r\n",
        "colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\r\n",
        "plt.scatter(datastack.T[0], datastack.T[1], c=colors)\r\n",
        "frame = plt.gca()\r\n",
        "frame.axes.get_xaxis().set_visible(False)\r\n",
        "frame.axes.get_yaxis().set_visible(False)\r\n",
        "plt.title('4 Clustering method: {}'.format(str(algorithm.__name__)),\r\n",
        "          fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dy1utMMfTz3"
      },
      "source": [
        "Vi har fortfarande inte sett en tydlig förbättring i prestanda av modellen. Det finns fler algoritmer att testa, dock de kommer inte att göra en förbättring för just den dataset. Om du vill kan du dock testa i kod 2a de följande algoritmer genom att substituera cluster.KMeans med cluster.AgglomerativeClustering eller cluster.SpectralClustering; välj antal kluster i kwargs med 'n_cluster' och ta bort 'random_state' parameter. Vi fortsätter här med någonting helt annorlunda:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVNdiBY-gsJH"
      },
      "source": [
        "5. DBSCAN står för density-based spatial clustering of application with noise. Som namnet antyder gör den en klustering baserat på density; hur tight punkter ligger tillsammans med sina grannar. DBSCAN visar ett tydlig överlägsen prestanda jämfört med de tidigare modeller. eps (epsilon) är en parameter som beskriver grannområdet från varje datapunkt modellen väljer som potentiell startpunkt för en kluster. min_samples står för minimal antal punkter som beskriver en 'dense region', alltså hur många punkter tight tillsammans är trovärdigt för dig som utgångspunkt (core point) för en kluster. Testa olika värden på dessa hyperparametrar i kwargs för att påverka klustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCZyAdBCdNaP"
      },
      "source": [
        "kwargs = {'eps': 0.25, 'min_samples': 5}\r\n",
        "\r\n",
        "algorithm = cluster.DBSCAN\r\n",
        "labels = algorithm(**kwargs).fit_predict(datastack)\r\n",
        "palette = sns.color_palette('muted', np.unique(labels).max() + 1)\r\n",
        "colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\r\n",
        "plt.scatter(datastack.T[0], datastack.T[1], c=colors)\r\n",
        "frame = plt.gca()\r\n",
        "frame.axes.get_xaxis().set_visible(False)\r\n",
        "frame.axes.get_yaxis().set_visible(False)\r\n",
        "plt.title('Clustering method: {}'.format(str(algorithm.__name__)),\r\n",
        "          fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTF5xYMWk9Va"
      },
      "source": [
        "6. Vi har sparat det bästa för sist. HDBSCAN är en optimerad DBSCAN, h står för hierarchical. Alla punkter har en attribut vilket beskriver hur starkt membership till en viss kluster är. Så vi kan plotta det som varierande saturation, för att visa skillnad mellan core och ytterkanten av en kluster. Detta är direkt användbart om man tänker riktig data; för nu kan vi visa skillnaden mellan kunder / produkten som är typiskt för en segment jämfört med kunder/produkter som kan tillhöra en segment men har vissa avvikande kännetecken."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mnoJedrih9n"
      },
      "source": [
        "clusterer = hdbscan.HDBSCAN(algorithm='best', alpha=1.0,\r\n",
        "                            approx_min_span_tree=True,\r\n",
        "                            gen_min_span_tree=True, leaf_size=40,\r\n",
        "                            metric='euclidean', min_cluster_size=6,\r\n",
        "                            min_samples=None, p=None,\r\n",
        "                            cluster_selection_method='eom')\r\n",
        "clusterer = clusterer.fit(datastack)\r\n",
        "palette = sns.color_palette('deep')\r\n",
        "cluster_colors = [sns.desaturate(palette[col], sat)\r\n",
        "                  if col >= 0 else (0.5, 0.5, 0.5) for col, sat in\r\n",
        "                  zip(clusterer.labels_, clusterer.probabilities_)]\r\n",
        "plt.scatter(datastack.T[0], datastack.T[1], c=cluster_colors, **plot_kwds)\r\n",
        "frame = plt.gca()\r\n",
        "frame.axes.get_xaxis().set_visible(False)\r\n",
        "frame.axes.get_yaxis().set_visible(False)\r\n",
        "plt.title('Clustering method: {} (leaf)'.format(str(hdbscan.HDBSCAN.__name__)),\r\n",
        "          fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z8esD2DmUQP"
      },
      "source": [
        "Om du vill leka mer så är det följande att rekommendera:\r\n",
        "* Gå till https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster och hitta olika algoritmer, du kan ta en algoritm diskuterat här och lägga till fler hyperparametrar för finetuning.\r\n",
        "\r\n",
        "* Ta datasettet från början och modulera den. Annorlunda dataset ger annorlunda prestanda av olika modeller. Om datasetet är enkelt så räcker det med enkel klustering. Dock du kommer att märka att (H)DBSCAN har överlägset prestanda och är ett bra klusteringval."
      ]
    }
  ]
}